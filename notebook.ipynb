{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEQggfTj0zhc"
      },
      "source": [
        "# VideoNetClassification\n",
        "\n",
        "Collaborators:\n",
        "\n",
        "- Yahia Ehab\n",
        "- Mariam Amr\n",
        "- Mohamed Khaled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJz1Sgeu0zhe"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akB0iCxB0zhf",
        "outputId": "5a6bc4a1-ae37-44b6-9cf5-e7f5c41b0d41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q imageio\n",
        "!pip install -q opencv-python\n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr__2D770zhg"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TDKA2Ulo0zhg"
      },
      "outputs": [],
      "source": [
        "# @title Import the necessary modules\n",
        "# TensorFlow and TF-Hub modules.\n",
        "from absl import logging\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow_docs.vis import embed\n",
        "\n",
        "logging.set_verbosity(logging.ERROR)\n",
        "\n",
        "# Some modules to help with reading the UCF101 dataset.\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import tempfile\n",
        "import ssl\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Some modules to display an animation using imageio.\n",
        "import imageio\n",
        "from IPython import display\n",
        "\n",
        "from urllib import request  # requires python3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y471aeoE0zhh"
      },
      "source": [
        "## Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jsU4LD9p0zhh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92dfa3fc-07ba-44b5-fe1f-174b450cfde1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_SkyDiving_g02_c01.avi => /tmp/tmp4gm92x_d/v_SkyDiving_g02_c01.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_WalkingWithDog_g11_c01.avi => /tmp/tmp4gm92x_d/v_WalkingWithDog_g11_c01.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_BabyCrawling_g11_c01.avi => /tmp/tmp4gm92x_d/v_BabyCrawling_g11_c01.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_Nunchucks_g01_c04.avi => /tmp/tmp4gm92x_d/v_Nunchucks_g01_c04.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_HorseRiding_g12_c02.avi => /tmp/tmp4gm92x_d/v_HorseRiding_g12_c02.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_PoleVault_g20_c04.avi => /tmp/tmp4gm92x_d/v_PoleVault_g20_c04.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_PlayingDhol_g06_c02.avi => /tmp/tmp4gm92x_d/v_PlayingDhol_g06_c02.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_Swing_g13_c02.avi => /tmp/tmp4gm92x_d/v_Swing_g13_c02.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_BalanceBeam_g22_c03.avi => /tmp/tmp4gm92x_d/v_BalanceBeam_g22_c03.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_ParallelBars_g13_c01.avi => /tmp/tmp4gm92x_d/v_ParallelBars_g13_c01.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_BlowDryHair_g06_c06.avi => /tmp/tmp4gm92x_d/v_BlowDryHair_g06_c06.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_ApplyEyeMakeup_g09_c03.avi => /tmp/tmp4gm92x_d/v_ApplyEyeMakeup_g09_c03.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_ApplyLipstick_g19_c04.avi => /tmp/tmp4gm92x_d/v_ApplyLipstick_g19_c04.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_PlayingCello_g25_c04.avi => /tmp/tmp4gm92x_d/v_PlayingCello_g25_c04.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_SoccerPenalty_g20_c05.avi => /tmp/tmp4gm92x_d/v_SoccerPenalty_g20_c05.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_Diving_g11_c05.avi => /tmp/tmp4gm92x_d/v_Diving_g11_c05.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_CliffDiving_g19_c05.avi => /tmp/tmp4gm92x_d/v_CliffDiving_g19_c05.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_BrushingTeeth_g07_c06.avi => /tmp/tmp4gm92x_d/v_BrushingTeeth_g07_c06.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_PlayingTabla_g09_c02.avi => /tmp/tmp4gm92x_d/v_PlayingTabla_g09_c02.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_Skiing_g05_c03.avi => /tmp/tmp4gm92x_d/v_Skiing_g05_c03.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_Biking_g01_c01.avi => /tmp/tmp4gm92x_d/v_Biking_g01_c01.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_JugglingBalls_g08_c05.avi => /tmp/tmp4gm92x_d/v_JugglingBalls_g08_c05.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_JumpRope_g23_c01.avi => /tmp/tmp4gm92x_d/v_JumpRope_g23_c01.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_Rafting_g13_c01.avi => /tmp/tmp4gm92x_d/v_Rafting_g13_c01.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_HandstandWalking_g11_c01.avi => /tmp/tmp4gm92x_d/v_HandstandWalking_g11_c01.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_FloorGymnastics_g23_c02.avi => /tmp/tmp4gm92x_d/v_FloorGymnastics_g23_c02.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_FieldHockeyPenalty_g22_c03.avi => /tmp/tmp4gm92x_d/v_FieldHockeyPenalty_g22_c03.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_Nunchucks_g10_c01.avi => /tmp/tmp4gm92x_d/v_Nunchucks_g10_c01.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_VolleyballSpiking_g22_c04.avi => /tmp/tmp4gm92x_d/v_VolleyballSpiking_g22_c04.avi\n",
            "Fetching https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_Bowling_g13_c04.avi => /tmp/tmp4gm92x_d/v_Bowling_g13_c04.avi\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Helper functions for the UCF101 dataset\n",
        "UCF_ROOT = \"https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/\"\n",
        "_VIDEO_LIST = None\n",
        "_CACHE_DIR = tempfile.mkdtemp()\n",
        "unverified_context = ssl._create_unverified_context()\n",
        "\n",
        "def list_ucf_videos():\n",
        "    \"\"\"Lists videos available in UCF101 dataset.\"\"\"\n",
        "    global _VIDEO_LIST\n",
        "    if not _VIDEO_LIST:\n",
        "        index = request.urlopen(UCF_ROOT, context=unverified_context).read().decode(\"utf-8\")\n",
        "        videos = re.findall(\"(v_[\\w_]+\\.avi)\", index)\n",
        "        _VIDEO_LIST = sorted(set(videos))\n",
        "    return list(_VIDEO_LIST)\n",
        "\n",
        "def fetch_ucf_video(video):\n",
        "    \"\"\"Fetches a video and cache into local filesystem.\"\"\"\n",
        "    cache_path = os.path.join(_CACHE_DIR, video)\n",
        "    if not os.path.exists(cache_path):\n",
        "        urlpath = request.urljoin(UCF_ROOT, video)\n",
        "        print(\"Fetching %s => %s\" % (urlpath, cache_path))\n",
        "        data = request.urlopen(urlpath, context=unverified_context).read()\n",
        "        open(cache_path, \"wb\").write(data)\n",
        "    return cache_path\n",
        "\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]\n",
        "\n",
        "def load_video(path, max_frames=30, resize=(224, 224)):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            frames.append(frame)\n",
        "\n",
        "            if max_frames != 0 and len(frames) == max_frames:\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return np.array(frames) / 255.0\n",
        "\n",
        "def to_gif(images):\n",
        "    converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
        "    imageio.mimsave('./animation.gif', converted_images, duration=40)\n",
        "    return embed.embed_file('./animation.gif')\n",
        "\n",
        "# Define a function to create DataFrame with video paths and labels\n",
        "def create_dataframe(num_videos=30):\n",
        "    video_paths = []\n",
        "    labels = []\n",
        "\n",
        "    # List all UCF101 videos\n",
        "    ucf_videos = list_ucf_videos()\n",
        "\n",
        "    # Randomly select videos\n",
        "    random_videos = random.sample(ucf_videos, num_videos)\n",
        "\n",
        "    # Extract labels from video filenames\n",
        "    for video in random_videos:\n",
        "        label = video.split('_')[1]\n",
        "        video_paths.append(fetch_ucf_video(video))\n",
        "        labels.append(label)\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame({'video_paths': video_paths, 'labels': labels})\n",
        "    return df\n",
        "\n",
        "# Create DataFrame with video paths and labels\n",
        "df = create_dataframe()\n",
        "\n",
        "# # Display the DataFrame\n",
        "# print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "W_ae8p8y0zhi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('ucf101_videos_labels.csv', index=False)\n",
        "#df = pd.read_csv('ucf101_videos_labels.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "J1CK3niM0zhi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ec6a1492-c3ab-4e4a-8ef1-3d8cde7987da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     video_paths          labels\n",
              "0       /tmp/tmp4gm92x_d/v_SkyDiving_g02_c01.avi       SkyDiving\n",
              "1  /tmp/tmp4gm92x_d/v_WalkingWithDog_g11_c01.avi  WalkingWithDog\n",
              "2    /tmp/tmp4gm92x_d/v_BabyCrawling_g11_c01.avi    BabyCrawling\n",
              "3       /tmp/tmp4gm92x_d/v_Nunchucks_g01_c04.avi       Nunchucks\n",
              "4     /tmp/tmp4gm92x_d/v_HorseRiding_g12_c02.avi     HorseRiding"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61bdbfae-dc92-435e-b050-939d2e82b904\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_paths</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/tmp/tmp4gm92x_d/v_SkyDiving_g02_c01.avi</td>\n",
              "      <td>SkyDiving</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/tmp/tmp4gm92x_d/v_WalkingWithDog_g11_c01.avi</td>\n",
              "      <td>WalkingWithDog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/tmp/tmp4gm92x_d/v_BabyCrawling_g11_c01.avi</td>\n",
              "      <td>BabyCrawling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/tmp/tmp4gm92x_d/v_Nunchucks_g01_c04.avi</td>\n",
              "      <td>Nunchucks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/tmp/tmp4gm92x_d/v_HorseRiding_g12_c02.avi</td>\n",
              "      <td>HorseRiding</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61bdbfae-dc92-435e-b050-939d2e82b904')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-61bdbfae-dc92-435e-b050-939d2e82b904 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-61bdbfae-dc92-435e-b050-939d2e82b904');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-619ed20b-c213-4f89-8832-b0659e948ad9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-619ed20b-c213-4f89-8832-b0659e948ad9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-619ed20b-c213-4f89-8832-b0659e948ad9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"video_paths\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"/tmp/tmp4gm92x_d/v_Nunchucks_g10_c01.avi\",\n          \"/tmp/tmp4gm92x_d/v_Diving_g11_c05.avi\",\n          \"/tmp/tmp4gm92x_d/v_Rafting_g13_c01.avi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"VolleyballSpiking\",\n          \"CliffDiving\",\n          \"ApplyLipstick\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZmLaQdHZ0zhi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "989336ae-eb3b-4d0b-c35e-db10a30d950b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/tmp/tmp4gm92x_d/v_SkyDiving_g02_c01.avi'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df['video_paths'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWaVIWz_0zhi"
      },
      "source": [
        "### Load Video as GIF\n",
        "\n",
        "Create `/GIFs` dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KcoDGfHu0zhj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e32f36e3-380f-4c2d-d415-748f45d520f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished video:  0\n",
            "finished video:  1\n",
            "finished video:  2\n",
            "finished video:  3\n",
            "finished video:  4\n",
            "finished video:  5\n",
            "finished video:  6\n",
            "finished video:  7\n",
            "finished video:  8\n",
            "finished video:  9\n",
            "finished video:  10\n",
            "finished video:  11\n",
            "finished video:  12\n",
            "finished video:  13\n",
            "finished video:  14\n",
            "finished video:  15\n",
            "finished video:  16\n",
            "finished video:  17\n",
            "finished video:  18\n",
            "finished video:  19\n"
          ]
        }
      ],
      "source": [
        "frames_clip = [] # a '2d' array where each element is a group of frames corresponding to one video\n",
        "for i in range(0, 20):\n",
        "    # Load the first video from the DataFrame\n",
        "    video_path = df['video_paths'][i]\n",
        "    video = load_video(video_path)\n",
        "    converted_video = np.clip(video*255, 0, 255).astype(np.uint8)\n",
        "    frames_clip.append(converted_video)\n",
        "    print(\"finished video: \", i)\n",
        "\n",
        "# extract labels from the dataframe\n",
        "labels = df['labels'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JMzMXoxZ0zhk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c925a507-1378-421e-db89-dd2a4e39a586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished video:  0\n",
            "finished video:  1\n",
            "finished video:  2\n",
            "finished video:  3\n",
            "finished video:  4\n",
            "finished video:  5\n",
            "finished video:  6\n",
            "finished video:  7\n",
            "finished video:  8\n",
            "finished video:  9\n",
            "finished video:  10\n",
            "finished video:  11\n",
            "finished video:  12\n",
            "finished video:  13\n",
            "finished video:  14\n",
            "finished video:  15\n",
            "finished video:  16\n",
            "finished video:  17\n",
            "finished video:  18\n",
            "finished video:  19\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "\n",
        "preprocessed = []\n",
        "for i in range(0, 20):\n",
        "    preprocessed.append(preprocess_input(frames_clip[i]))\n",
        "    print(\"finished video: \", i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrVEFjKi0zhl"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "- CNN (InceptionV3 Model)\n",
        "    1. Image Size should be 299*299 (only if we're using the full model)\n",
        "\n",
        "- RNN\n",
        "    1. LTSM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzY2t_UV0zhl"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_0AgL0tN0zhl"
      },
      "outputs": [],
      "source": [
        "# Load the InceptionV3 model from TensorFlow Hub\n",
        "feature_extractor = hub.KerasLayer(\n",
        "    \"https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4\", trainable=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Bkrr-GBb0zhm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "651c7793-4b7e-4768-f4fb-a22ae8c501df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        }
      ],
      "source": [
        "# Function to extract features using InceptionV3\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "\n",
        "def extract_video_features(video_frames):\n",
        "    base_model = InceptionV3(weights='imagenet', include_top=False, pooling='avg')\n",
        "    video_features = []\n",
        "    for video in video_frames:\n",
        "        video_features.append(base_model.predict(video))\n",
        "    return np.array(video_features)\n",
        "\n",
        "video_features = extract_video_features(preprocessed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "r6hl1UrkVPvQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "788e7450-c336-470d-f5f4-67abcc33a521"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02520531, 0.16635466, 0.13847682, ..., 0.5598354 , 0.04727876,\n",
              "        0.09656119],\n",
              "       [0.13674994, 0.40171912, 0.05338402, ..., 0.25148198, 0.08858455,\n",
              "        0.20174764],\n",
              "       [0.15211831, 0.48810428, 0.11202975, ..., 0.02530198, 0.33688548,\n",
              "        0.01934987],\n",
              "       ...,\n",
              "       [0.06045878, 0.7241143 , 0.1619721 , ..., 0.0111265 , 1.1488131 ,\n",
              "        0.3639871 ],\n",
              "       [0.22813064, 0.49462834, 0.19611564, ..., 0.07709448, 0.16632149,\n",
              "        0.7587653 ],\n",
              "       [0.43994546, 0.13805006, 0.13357519, ..., 0.07446862, 0.6358732 ,\n",
              "        0.31239206]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "video_features[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "1pksFrsiM3zm"
      },
      "outputs": [],
      "source": [
        "split_index = int(0.8 * len(video_features))\n",
        "train, test = video_features[:split_index], video_features[split_index:]\n",
        "train_labels, test_labels = labels[:split_index], labels[split_index:20]\n",
        "split = int(0.8*len(train))\n",
        "train_features, validate_features = train[:split], train[split:]\n",
        "train_labels, validate_labels = train_labels[:split], train_labels[split:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLRfyVtFO3t2",
        "outputId": "3c03642c-99b6-4d14-b2c8-62c99e7b9570"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 30, 2048)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WU1OThncVZtV"
      },
      "outputs": [],
      "source": [
        "max = 0\n",
        "for i in range(0, len(train_features)):\n",
        "  if train_features[i].shape[1] > max:\n",
        "    max = train_features[i].shape[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for label in labels:\n",
        "  print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57p2ww69SQeJ",
        "outputId": "473f1afb-711d-4b40-d125-8e9bd0fb0422"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SkyDiving\n",
            "WalkingWithDog\n",
            "BabyCrawling\n",
            "Nunchucks\n",
            "HorseRiding\n",
            "PoleVault\n",
            "PlayingDhol\n",
            "Swing\n",
            "BalanceBeam\n",
            "ParallelBars\n",
            "BlowDryHair\n",
            "ApplyEyeMakeup\n",
            "ApplyLipstick\n",
            "PlayingCello\n",
            "SoccerPenalty\n",
            "Diving\n",
            "CliffDiving\n",
            "BrushingTeeth\n",
            "PlayingTabla\n",
            "Skiing\n",
            "Biking\n",
            "JugglingBalls\n",
            "JumpRope\n",
            "Rafting\n",
            "HandstandWalking\n",
            "FloorGymnastics\n",
            "FieldHockeyPenalty\n",
            "Nunchucks\n",
            "VolleyballSpiking\n",
            "Bowling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create a LabelEncoder object\n",
        "label_encoder = LabelEncoder()\n",
        "# Fit the LabelEncoder on the training labels\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "# Transform the validation labels using the fitted LabelEncoder\n",
        "validate_labels_encoded = label_encoder.fit_transform(validate_labels)\n",
        "train_labels_onehot = to_categorical(train_labels_encoded)\n",
        "validate_labels_onehot = to_categorical(validate_labels_encoded)\n",
        "#train_labels_onehot = np.reshape(train_labels_onehot, (train_labels_onehot.shape[0], 30))\n",
        "train_labels_onehot.ndim()\n",
        "#validate_labels_onehot = np.reshape(validate_labels_onehot, (validate_labels_onehot.shape[0], 30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "YlmY6rHvN2iB",
        "outputId": "e0ddfcf6-791b-41c6-e427-feb0bee4fa6a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'int' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-4a29c38a3901>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mvalidate_labels_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate_labels_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#train_labels_onehot = np.reshape(train_labels_onehot, (train_labels_onehot.shape[0], 30))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrain_labels_onehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#validate_labels_onehot = np.reshape(validate_labels_onehot, (validate_labels_onehot.shape[0], 30))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_onehot.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMs2EIcvaXMs",
        "outputId": "83dc1d82-c29c-4a3c-ca3c-db584db78845"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "FdeeRAItAhTo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "outputId": "6ad76f65-86c4-4ff2-d344-1b31311be9f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 12) and (None, 30) are incompatible\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-970326df0b96>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mrnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mrnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_labels_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 12) and (None, 30) are incompatible\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# RNN model creation\n",
        "rnn_model = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(30, 2048)),\n",
        "    LSTM(64),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(labels), activation='softmax')\n",
        "])\n",
        "\n",
        "rnn_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "rnn_model.fit(train_features, train_labels_onehot, validation_data=(validate_features, validate_labels_onehot), epochs=4)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}